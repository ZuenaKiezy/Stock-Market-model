{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Amazon.csv\",parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.927083</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>72156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>1.979167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>14700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>1.760417</td>\n",
       "      <td>1.770833</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>6106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>5467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>18853200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1997-05-22</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>1.447917</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>11776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997-05-23</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>1.520833</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>15937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997-05-27</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.458333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>8697600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1997-05-28</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>4574400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1997-05-29</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>3472800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close    Volume\n",
       "0 1997-05-15  2.437500  2.500000  1.927083  1.958333   1.958333  72156000\n",
       "1 1997-05-16  1.968750  1.979167  1.708333  1.729167   1.729167  14700000\n",
       "2 1997-05-19  1.760417  1.770833  1.625000  1.708333   1.708333   6106800\n",
       "3 1997-05-20  1.729167  1.750000  1.635417  1.635417   1.635417   5467200\n",
       "4 1997-05-21  1.635417  1.645833  1.375000  1.427083   1.427083  18853200\n",
       "5 1997-05-22  1.437500  1.447917  1.312500  1.395833   1.395833  11776800\n",
       "6 1997-05-23  1.406250  1.520833  1.333333  1.500000   1.500000  15937200\n",
       "7 1997-05-27  1.510417  1.645833  1.458333  1.583333   1.583333   8697600\n",
       "8 1997-05-28  1.625000  1.635417  1.531250  1.531250   1.531250   4574400\n",
       "9 1997-05-29  1.541667  1.541667  1.479167  1.505208   1.505208   3472800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>3414.25000</td>\n",
       "      <td>3440.280029</td>\n",
       "      <td>3403.000000</td>\n",
       "      <td>3435.010010</td>\n",
       "      <td>3435.010010</td>\n",
       "      <td>1881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>3421.00000</td>\n",
       "      <td>3429.840088</td>\n",
       "      <td>3331.300049</td>\n",
       "      <td>3335.550049</td>\n",
       "      <td>3335.550049</td>\n",
       "      <td>3133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>3335.00000</td>\n",
       "      <td>3347.800049</td>\n",
       "      <td>3297.699951</td>\n",
       "      <td>3320.370117</td>\n",
       "      <td>3320.370117</td>\n",
       "      <td>2226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>3349.51001</td>\n",
       "      <td>3416.120117</td>\n",
       "      <td>3343.979980</td>\n",
       "      <td>3376.070068</td>\n",
       "      <td>3376.070068</td>\n",
       "      <td>2693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>3388.00000</td>\n",
       "      <td>3412.000000</td>\n",
       "      <td>3371.453369</td>\n",
       "      <td>3396.189941</td>\n",
       "      <td>3396.189941</td>\n",
       "      <td>1080291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open         High          Low        Close  \\\n",
       "6150 2021-10-21  3414.25000  3440.280029  3403.000000  3435.010010   \n",
       "6151 2021-10-22  3421.00000  3429.840088  3331.300049  3335.550049   \n",
       "6152 2021-10-25  3335.00000  3347.800049  3297.699951  3320.370117   \n",
       "6153 2021-10-26  3349.51001  3416.120117  3343.979980  3376.070068   \n",
       "6154 2021-10-27  3388.00000  3412.000000  3371.453369  3396.189941   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "6150  3435.010010  1881400  \n",
       "6151  3335.550049  3133800  \n",
       "6152  3320.370117  2226000  \n",
       "6153  3376.070068  2693700  \n",
       "6154  3396.189941  1080291  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6155 entries, 0 to 6154\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       6155 non-null   datetime64[ns]\n",
      " 1   Open       6155 non-null   float64       \n",
      " 2   High       6155 non-null   float64       \n",
      " 3   Low        6155 non-null   float64       \n",
      " 4   Close      6155 non-null   float64       \n",
      " 5   Adj Close  6155 non-null   float64       \n",
      " 6   Volume     6155 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1)\n",
      "memory usage: 336.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6155, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         False\n",
       "Open         False\n",
       "High         False\n",
       "Low          False\n",
       "Close        False\n",
       "Adj Close    False\n",
       "Volume       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"Open\",\"Close\",\"High\",\"Low\",\"Adj Close\"]\n",
    "for col in cols:\n",
    "    data[col]=data[col].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6155 entries, 0 to 6154\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       6155 non-null   datetime64[ns]\n",
      " 1   Open       6155 non-null   float64       \n",
      " 2   High       6155 non-null   float64       \n",
      " 3   Low        6155 non-null   float64       \n",
      " 4   Close      6155 non-null   float64       \n",
      " 5   Adj Close  6155 non-null   float64       \n",
      " 6   Volume     6155 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1)\n",
      "memory usage: 336.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         datetime64[ns]\n",
       "Open                float64\n",
       "High                float64\n",
       "Low                 float64\n",
       "Close               float64\n",
       "Adj Close           float64\n",
       "Volume                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return features\n",
    "data[\"daily_return\"]=data[\"Adj Close\"].pct_change()\n",
    "data[\"log_return\"]=np.log(data[\"Adj Close\"]/ data[\"Adj Close\"].shift(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price Ratios\n",
    "data[\"close_open_ratio\"]=data[\"Close\"]/data[\"Open\"]\n",
    "data[\"high_low_ratio\"]=data[\"High\"]/data[\"Low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving averages\n",
    "data[\"simple_avg_5\"]=data[\"Adj Close\"].rolling(window=5).mean()\n",
    "data[\"simple_avg_10\"]=data[\"Adj Close\"].rolling(window=10).mean()\n",
    "data[\"exponential_avg_10\"]=data[\"Adj Close\"].ewm(span=10,adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatility measures\n",
    "data[\"volatility_5\"]=data[\"daily_return\"].rolling(window=5).std()\n",
    "data[\"volatility_10\"]=data[\"daily_return\"].rolling(window=10).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lag features\n",
    "data[\"adj_close_lag1\"]=data[\"Adj Close\"].shift(1)\n",
    "data[\"adj_close_lag5\"]=data[\"Adj Close\"].shift(5)\n",
    "data[\"daily_return_lag1\"]=data[\"daily_return\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>log_return</th>\n",
       "      <th>close_open_ratio</th>\n",
       "      <th>high_low_ratio</th>\n",
       "      <th>simple_avg_5</th>\n",
       "      <th>simple_avg_10</th>\n",
       "      <th>exponential_avg_10</th>\n",
       "      <th>volatility_5</th>\n",
       "      <th>volatility_10</th>\n",
       "      <th>adj_close_lag1</th>\n",
       "      <th>adj_close_lag5</th>\n",
       "      <th>daily_return_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.927083</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>72156000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>1.297298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>1.979167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>14700000</td>\n",
       "      <td>-0.117021</td>\n",
       "      <td>-0.124454</td>\n",
       "      <td>0.878307</td>\n",
       "      <td>1.158537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.916666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>1.760417</td>\n",
       "      <td>1.770833</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>6106800</td>\n",
       "      <td>-0.012049</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>0.970414</td>\n",
       "      <td>1.089743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.878788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.117021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>5467200</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>-0.043620</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>1.070063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.834538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>18853200</td>\n",
       "      <td>-0.127389</td>\n",
       "      <td>-0.136265</td>\n",
       "      <td>0.872611</td>\n",
       "      <td>1.196969</td>\n",
       "      <td>1.691667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.760456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.042683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1997-05-22</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>1.447917</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>11776800</td>\n",
       "      <td>-0.021898</td>\n",
       "      <td>-0.022141</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>1.103175</td>\n",
       "      <td>1.579167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694161</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>-0.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997-05-23</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>1.520833</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>15937200</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.071974</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>1.140625</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.658859</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>-0.021898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997-05-27</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.458333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>8697600</td>\n",
       "      <td>0.055555</td>\n",
       "      <td>0.054067</td>\n",
       "      <td>1.048275</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>1.508333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645127</td>\n",
       "      <td>0.081273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>0.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1997-05-28</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>4574400</td>\n",
       "      <td>-0.032895</td>\n",
       "      <td>-0.033448</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>1.068027</td>\n",
       "      <td>1.487500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624422</td>\n",
       "      <td>0.080474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>0.055555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1997-05-29</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>3472800</td>\n",
       "      <td>-0.017007</td>\n",
       "      <td>-0.017153</td>\n",
       "      <td>0.976351</td>\n",
       "      <td>1.042254</td>\n",
       "      <td>1.503125</td>\n",
       "      <td>1.597396</td>\n",
       "      <td>1.602747</td>\n",
       "      <td>0.049560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>-0.032895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
       "0 1997-05-15  2.437500  2.500000  1.927083  1.958333   1.958333  72156000   \n",
       "1 1997-05-16  1.968750  1.979167  1.708333  1.729167   1.729167  14700000   \n",
       "2 1997-05-19  1.760417  1.770833  1.625000  1.708333   1.708333   6106800   \n",
       "3 1997-05-20  1.729167  1.750000  1.635417  1.635417   1.635417   5467200   \n",
       "4 1997-05-21  1.635417  1.645833  1.375000  1.427083   1.427083  18853200   \n",
       "5 1997-05-22  1.437500  1.447917  1.312500  1.395833   1.395833  11776800   \n",
       "6 1997-05-23  1.406250  1.520833  1.333333  1.500000   1.500000  15937200   \n",
       "7 1997-05-27  1.510417  1.645833  1.458333  1.583333   1.583333   8697600   \n",
       "8 1997-05-28  1.625000  1.635417  1.531250  1.531250   1.531250   4574400   \n",
       "9 1997-05-29  1.541667  1.541667  1.479167  1.505208   1.505208   3472800   \n",
       "\n",
       "   daily_return  log_return  close_open_ratio  high_low_ratio  simple_avg_5  \\\n",
       "0           NaN         NaN          0.803419        1.297298           NaN   \n",
       "1     -0.117021   -0.124454          0.878307        1.158537           NaN   \n",
       "2     -0.012049   -0.012122          0.970414        1.089743           NaN   \n",
       "3     -0.042683   -0.043620          0.945783        1.070063           NaN   \n",
       "4     -0.127389   -0.136265          0.872611        1.196969      1.691667   \n",
       "5     -0.021898   -0.022141          0.971014        1.103175      1.579167   \n",
       "6      0.074627    0.071974          1.066667        1.140625      1.533333   \n",
       "7      0.055555    0.054067          1.048275        1.128571      1.508333   \n",
       "8     -0.032895   -0.033448          0.942308        1.068027      1.487500   \n",
       "9     -0.017007   -0.017153          0.976351        1.042254      1.503125   \n",
       "\n",
       "   simple_avg_10  exponential_avg_10  volatility_5  volatility_10  \\\n",
       "0            NaN            1.958333           NaN            NaN   \n",
       "1            NaN            1.916666           NaN            NaN   \n",
       "2            NaN            1.878788           NaN            NaN   \n",
       "3            NaN            1.834538           NaN            NaN   \n",
       "4            NaN            1.760456           NaN            NaN   \n",
       "5            NaN            1.694161      0.054211            NaN   \n",
       "6            NaN            1.658859      0.072276            NaN   \n",
       "7            NaN            1.645127      0.081273            NaN   \n",
       "8            NaN            1.624422      0.080474            NaN   \n",
       "9       1.597396            1.602747      0.049560            NaN   \n",
       "\n",
       "   adj_close_lag1  adj_close_lag5  daily_return_lag1  \n",
       "0             NaN             NaN                NaN  \n",
       "1        1.958333             NaN                NaN  \n",
       "2        1.729167             NaN          -0.117021  \n",
       "3        1.708333             NaN          -0.012049  \n",
       "4        1.635417             NaN          -0.042683  \n",
       "5        1.427083        1.958333          -0.127389  \n",
       "6        1.395833        1.729167          -0.021898  \n",
       "7        1.500000        1.708333           0.074627  \n",
       "8        1.583333        1.635417           0.055555  \n",
       "9        1.531250        1.427083          -0.032895  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>log_return</th>\n",
       "      <th>close_open_ratio</th>\n",
       "      <th>high_low_ratio</th>\n",
       "      <th>simple_avg_5</th>\n",
       "      <th>simple_avg_10</th>\n",
       "      <th>exponential_avg_10</th>\n",
       "      <th>volatility_5</th>\n",
       "      <th>volatility_10</th>\n",
       "      <th>adj_close_lag1</th>\n",
       "      <th>adj_close_lag5</th>\n",
       "      <th>daily_return_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.927083</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>72156000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>1.297298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>1.979167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>14700000</td>\n",
       "      <td>-0.117021</td>\n",
       "      <td>-0.124454</td>\n",
       "      <td>0.878307</td>\n",
       "      <td>1.158537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.916666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>1.760417</td>\n",
       "      <td>1.770833</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>6106800</td>\n",
       "      <td>-0.012049</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>0.970414</td>\n",
       "      <td>1.089743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.878788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.117021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>5467200</td>\n",
       "      <td>-0.042683</td>\n",
       "      <td>-0.043620</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>1.070063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.834538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>18853200</td>\n",
       "      <td>-0.127389</td>\n",
       "      <td>-0.136265</td>\n",
       "      <td>0.872611</td>\n",
       "      <td>1.196969</td>\n",
       "      <td>1.691667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.760456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.042683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1997-05-22</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>1.447917</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>11776800</td>\n",
       "      <td>-0.021898</td>\n",
       "      <td>-0.022141</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>1.103175</td>\n",
       "      <td>1.579167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.694161</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>-0.127389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997-05-23</td>\n",
       "      <td>1.406250</td>\n",
       "      <td>1.520833</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>15937200</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.071974</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>1.140625</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.658859</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>-0.021898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1997-05-27</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.645833</td>\n",
       "      <td>1.458333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>8697600</td>\n",
       "      <td>0.055555</td>\n",
       "      <td>0.054067</td>\n",
       "      <td>1.048275</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>1.508333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.645127</td>\n",
       "      <td>0.081273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>0.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1997-05-28</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>4574400</td>\n",
       "      <td>-0.032895</td>\n",
       "      <td>-0.033448</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>1.068027</td>\n",
       "      <td>1.487500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.624422</td>\n",
       "      <td>0.080474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>0.055555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1997-05-29</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>3472800</td>\n",
       "      <td>-0.017007</td>\n",
       "      <td>-0.017153</td>\n",
       "      <td>0.976351</td>\n",
       "      <td>1.042254</td>\n",
       "      <td>1.503125</td>\n",
       "      <td>1.597396</td>\n",
       "      <td>1.602747</td>\n",
       "      <td>0.049560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>-0.032895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
       "0 1997-05-15  2.437500  2.500000  1.927083  1.958333   1.958333  72156000   \n",
       "1 1997-05-16  1.968750  1.979167  1.708333  1.729167   1.729167  14700000   \n",
       "2 1997-05-19  1.760417  1.770833  1.625000  1.708333   1.708333   6106800   \n",
       "3 1997-05-20  1.729167  1.750000  1.635417  1.635417   1.635417   5467200   \n",
       "4 1997-05-21  1.635417  1.645833  1.375000  1.427083   1.427083  18853200   \n",
       "5 1997-05-22  1.437500  1.447917  1.312500  1.395833   1.395833  11776800   \n",
       "6 1997-05-23  1.406250  1.520833  1.333333  1.500000   1.500000  15937200   \n",
       "7 1997-05-27  1.510417  1.645833  1.458333  1.583333   1.583333   8697600   \n",
       "8 1997-05-28  1.625000  1.635417  1.531250  1.531250   1.531250   4574400   \n",
       "9 1997-05-29  1.541667  1.541667  1.479167  1.505208   1.505208   3472800   \n",
       "\n",
       "   daily_return  log_return  close_open_ratio  high_low_ratio  simple_avg_5  \\\n",
       "0           NaN         NaN          0.803419        1.297298           NaN   \n",
       "1     -0.117021   -0.124454          0.878307        1.158537           NaN   \n",
       "2     -0.012049   -0.012122          0.970414        1.089743           NaN   \n",
       "3     -0.042683   -0.043620          0.945783        1.070063           NaN   \n",
       "4     -0.127389   -0.136265          0.872611        1.196969      1.691667   \n",
       "5     -0.021898   -0.022141          0.971014        1.103175      1.579167   \n",
       "6      0.074627    0.071974          1.066667        1.140625      1.533333   \n",
       "7      0.055555    0.054067          1.048275        1.128571      1.508333   \n",
       "8     -0.032895   -0.033448          0.942308        1.068027      1.487500   \n",
       "9     -0.017007   -0.017153          0.976351        1.042254      1.503125   \n",
       "\n",
       "   simple_avg_10  exponential_avg_10  volatility_5  volatility_10  \\\n",
       "0            NaN            1.958333           NaN            NaN   \n",
       "1            NaN            1.916666           NaN            NaN   \n",
       "2            NaN            1.878788           NaN            NaN   \n",
       "3            NaN            1.834538           NaN            NaN   \n",
       "4            NaN            1.760456           NaN            NaN   \n",
       "5            NaN            1.694161      0.054211            NaN   \n",
       "6            NaN            1.658859      0.072276            NaN   \n",
       "7            NaN            1.645127      0.081273            NaN   \n",
       "8            NaN            1.624422      0.080474            NaN   \n",
       "9       1.597396            1.602747      0.049560            NaN   \n",
       "\n",
       "   adj_close_lag1  adj_close_lag5  daily_return_lag1  \n",
       "0             NaN             NaN                NaN  \n",
       "1        1.958333             NaN                NaN  \n",
       "2        1.729167             NaN          -0.117021  \n",
       "3        1.708333             NaN          -0.012049  \n",
       "4        1.635417             NaN          -0.042683  \n",
       "5        1.427083        1.958333          -0.127389  \n",
       "6        1.395833        1.729167          -0.021898  \n",
       "7        1.500000        1.708333           0.074627  \n",
       "8        1.583333        1.635417           0.055555  \n",
       "9        1.531250        1.427083          -0.032895  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>log_return</th>\n",
       "      <th>close_open_ratio</th>\n",
       "      <th>high_low_ratio</th>\n",
       "      <th>simple_avg_5</th>\n",
       "      <th>simple_avg_10</th>\n",
       "      <th>exponential_avg_10</th>\n",
       "      <th>volatility_5</th>\n",
       "      <th>volatility_10</th>\n",
       "      <th>adj_close_lag1</th>\n",
       "      <th>adj_close_lag5</th>\n",
       "      <th>daily_return_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1997-05-30</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2594400</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>-0.003466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.021127</td>\n",
       "      <td>1.523958</td>\n",
       "      <td>1.551562</td>\n",
       "      <td>1.584065</td>\n",
       "      <td>0.047060</td>\n",
       "      <td>0.063633</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>-0.017007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1997-06-02</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>591600</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.020833</td>\n",
       "      <td>1.526042</td>\n",
       "      <td>1.529687</td>\n",
       "      <td>1.570675</td>\n",
       "      <td>0.033545</td>\n",
       "      <td>0.055091</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.003460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1997-06-03</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1183200</td>\n",
       "      <td>-0.020690</td>\n",
       "      <td>-0.020907</td>\n",
       "      <td>0.965987</td>\n",
       "      <td>1.035211</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.506771</td>\n",
       "      <td>1.554037</td>\n",
       "      <td>0.015483</td>\n",
       "      <td>0.055159</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.006945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1997-06-04</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.489583</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>3080400</td>\n",
       "      <td>-0.042254</td>\n",
       "      <td>-0.043172</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>1.067164</td>\n",
       "      <td>1.482292</td>\n",
       "      <td>1.484896</td>\n",
       "      <td>1.529061</td>\n",
       "      <td>0.018665</td>\n",
       "      <td>0.055134</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>-0.020690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1997-06-05</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>5672400</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.084557</td>\n",
       "      <td>1.088235</td>\n",
       "      <td>1.121212</td>\n",
       "      <td>1.489584</td>\n",
       "      <td>1.496354</td>\n",
       "      <td>1.531353</td>\n",
       "      <td>0.049733</td>\n",
       "      <td>0.046911</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>-0.042254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close   Volume  \\\n",
       "10 1997-05-30  1.500000  1.510417  1.479167  1.500000   1.500000  2594400   \n",
       "11 1997-06-02  1.510417  1.531250  1.500000  1.510417   1.510417   591600   \n",
       "12 1997-06-03  1.531250  1.531250  1.479167  1.479167   1.479167  1183200   \n",
       "13 1997-06-04  1.479167  1.489583  1.395833  1.416667   1.416667  3080400   \n",
       "14 1997-06-05  1.416667  1.541667  1.375000  1.541667   1.541667  5672400   \n",
       "\n",
       "    daily_return  log_return  close_open_ratio  high_low_ratio  simple_avg_5  \\\n",
       "10     -0.003460   -0.003466          1.000000        1.021127      1.523958   \n",
       "11      0.006945    0.006921          1.000000        1.020833      1.526042   \n",
       "12     -0.020690   -0.020907          0.965987        1.035211      1.505208   \n",
       "13     -0.042254   -0.043172          0.957746        1.067164      1.482292   \n",
       "14      0.088235    0.084557          1.088235        1.121212      1.489584   \n",
       "\n",
       "    simple_avg_10  exponential_avg_10  volatility_5  volatility_10  \\\n",
       "10       1.551562            1.584065      0.047060       0.063633   \n",
       "11       1.529687            1.570675      0.033545       0.055091   \n",
       "12       1.506771            1.554037      0.015483       0.055159   \n",
       "13       1.484896            1.529061      0.018665       0.055134   \n",
       "14       1.496354            1.531353      0.049733       0.046911   \n",
       "\n",
       "    adj_close_lag1  adj_close_lag5  daily_return_lag1  \n",
       "10        1.505208        1.395833          -0.017007  \n",
       "11        1.500000        1.500000          -0.003460  \n",
       "12        1.510417        1.583333           0.006945  \n",
       "13        1.479167        1.531250          -0.020690  \n",
       "14        1.416667        1.505208          -0.042254  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x= data.drop([\"Date\",\"Close\",\"Open\"], axis=1, inplace=False) \n",
    "y=data[\"Adj Close\"]  \n",
    "#train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "scaler=MinMaxScaler()\n",
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_test_scaled=scaler.fit_transform(x_test)                                                 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the data for LSTM\n",
    "timesteps=60\n",
    "def create_sequence(x, y, timesteps):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x_seq, y_seq = [], []\n",
    "    for i in range(len(x) - timesteps):\n",
    "        x_seq.append(x[i:i + timesteps])\n",
    "        y_seq.append(y[i + timesteps])   \n",
    "    return np.array(x_seq), np.array(y_seq)\n",
    "x_train_seq,y_train_seq= create_sequence(x_train_scaled,y_train, timesteps)\n",
    "x_test_seq,y_test_seq= create_sequence(x_test_scaled,y_test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6145, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1169, 60, 16), (4856, 60, 16))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_seq.shape,x_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model1_lstm = Sequential()\n",
    "model1_lstm.add(LSTM(64, return_sequences=True, input_shape=(x_train_seq.shape[1], x_train_seq.shape[2])))\n",
    "model1_lstm.add(LSTM(64, return_sequences=False,))\n",
    "model1_lstm.add(Dense(128, activation='relu'))\n",
    "model1_lstm.add(Dropout(0.5))\n",
    "model1_lstm.add(Dense(1))\n",
    "model1_lstm.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - loss: 974802.1875 - val_loss: 862911.6875\n",
      "Epoch 2/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 836279.1875 - val_loss: 732287.8750\n",
      "Epoch 3/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - loss: 765230.1250 - val_loss: 698786.1250\n",
      "Epoch 4/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - loss: 751664.6250 - val_loss: 695967.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 750776.0000 - val_loss: 695503.1875\n",
      "Epoch 6/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - loss: 754585.3125 - val_loss: 695448.6250\n",
      "Epoch 7/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - loss: 753509.1250 - val_loss: 695457.5625\n",
      "Epoch 8/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 751840.1875 - val_loss: 695334.1250\n",
      "Epoch 9/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - loss: 749170.1875 - val_loss: 695663.6250\n",
      "Epoch 10/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 755228.6250 - val_loss: 695565.5625\n",
      "Epoch 11/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - loss: 751488.5625 - val_loss: 695397.3750\n",
      "Epoch 12/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - loss: 750286.6875 - val_loss: 695567.6875\n",
      "Epoch 13/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - loss: 750231.0000 - val_loss: 695430.8750\n",
      "Epoch 14/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - loss: 752634.6250 - val_loss: 695597.0625\n",
      "Epoch 15/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - loss: 748338.7500 - val_loss: 695221.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 753959.4375 - val_loss: 695362.1250\n",
      "Epoch 17/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 751726.0625 - val_loss: 695534.3125\n",
      "Epoch 18/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 752143.3125 - val_loss: 695688.3125\n",
      "Epoch 19/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 752520.8750 - val_loss: 695335.1875\n",
      "Epoch 20/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 756576.5625 - val_loss: 695406.6250\n",
      "Epoch 21/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - loss: 758214.0000 - val_loss: 695567.4375\n",
      "Epoch 22/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - loss: 747171.9375 - val_loss: 695270.5000\n",
      "Epoch 23/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step - loss: 752070.0000 - val_loss: 695343.8750\n",
      "Epoch 24/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 752310.5625 - val_loss: 695850.3125\n",
      "Epoch 25/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 753858.7500 - val_loss: 695636.1875\n",
      "Epoch 26/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - loss: 750032.6875 - val_loss: 695454.3750\n",
      "Epoch 27/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - loss: 752334.1250 - val_loss: 695371.5625\n",
      "Epoch 28/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - loss: 754495.6250 - val_loss: 695431.6875\n",
      "Epoch 29/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - loss: 754451.6875 - val_loss: 695256.0625\n",
      "Epoch 30/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - loss: 754855.3750 - val_loss: 695273.5625\n",
      "Epoch 31/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - loss: 752839.1250 - val_loss: 695591.1250\n",
      "Epoch 32/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 752913.1875 - val_loss: 695397.4375\n",
      "Epoch 33/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - loss: 749161.4375 - val_loss: 695343.3125\n",
      "Epoch 34/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - loss: 752078.6875 - val_loss: 695191.1875\n",
      "Epoch 35/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - loss: 755111.4375 - val_loss: 695613.1875\n",
      "Epoch 36/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - loss: 755532.9375 - val_loss: 695558.1250\n",
      "Epoch 37/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 756100.8125 - val_loss: 695942.0625\n",
      "Epoch 38/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 753616.1875 - val_loss: 695444.1250\n",
      "Epoch 39/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - loss: 755200.3750 - val_loss: 695486.6250\n",
      "Epoch 40/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 754645.9375 - val_loss: 695679.4375\n",
      "Epoch 41/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 753288.5625 - val_loss: 695430.1250\n",
      "Epoch 42/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - loss: 755756.2500 - val_loss: 695572.5625\n",
      "Epoch 43/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 751652.9375 - val_loss: 695420.2500\n",
      "Epoch 44/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - loss: 751741.8125 - val_loss: 695387.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - loss: 753263.0000 - val_loss: 695422.5000\n",
      "Epoch 46/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - loss: 753465.2500 - val_loss: 695738.5000\n",
      "Epoch 47/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - loss: 751962.4375 - val_loss: 695683.5625\n",
      "Epoch 48/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - loss: 750172.3125 - val_loss: 695585.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - loss: 750025.0000 - val_loss: 695277.9375\n",
      "Epoch 50/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - loss: 755738.3750 - val_loss: 695394.8125\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model1_lstm.fit(x_train_seq, y_train_seq, epochs=50, batch_size=32, validation_split=0.2)\n",
    "y_pred_lstm = model1_lstm.predict(x_test_seq)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
